{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping Data Science Jobs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarveshahuja1992/Webscraping-Indeed.com/blob/master/Scraping_Data_Science_Jobs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8-wv5hzjOmp"
      },
      "source": [
        "This project is to automate the job search process, Saving time by downloading relevant jobposts from Indeed.com in an excel file.\n",
        "**The first part of the code:**\n",
        "\n",
        "Uses **BeautifulSoup** to get the information from the search results webpage using elements on it, I extract the following data points: Position/Job title, Company Name, Location, Link to the jobpost. \n",
        "\n",
        "I have used **Pandas** to store this data in a dataframe and export to an excel sheet later.\n",
        "\n",
        "The second part of the code opens every job post link and extracts Company Rating, Job posting date and Job Description from each page. \n",
        "\n",
        "After extracting all this data, the **dataframe** is exported into an **excel sheet** and gets uploaded to a folder on **google drive**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1e3Pmv6qGaa",
        "outputId": "8c0c2498-00b0-43ff-da93-9ce499799669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "# Importing Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import re\n",
        "#Creating a python list to store all the data points before it is converted to a dataframe. \n",
        "results = []\n",
        "with requests.Session() as s:\n",
        "    for i in range(0,500):\n",
        "      #(10*i) is the page number to be looked for and the keywords can be specified after q= and l= in the link below\n",
        "        url = 'https://www.indeed.com/jobs?q=data+science&l=United+States&explvl=entry_level&sort=date&start='+str(10*i)\n",
        "        #Extracting the content from webpage\n",
        "        res = s.get(url.format(url))\n",
        "        soup = bs(res.content, 'lxml')\n",
        "        #Creating lists for required data points\n",
        "        titles = [item.text.strip() for item in soup.select('[data-tn-element=jobTitle]')]\n",
        "        companies = [item.text.strip() for item in soup.select('.company')]\n",
        "        spans = soup.find_all('span',{'class':'location accessible-contrast-color-location'})\n",
        "        lines = [span.get_text() for span in spans]\n",
        "        links = []\n",
        "        all_a = soup.select('[data-tn-element=jobTitle]')\n",
        "        for a in all_a:\n",
        "            links.append(a['href'])\n",
        "        # Zipping all iterables in the lists\n",
        "        data = list(zip(titles, companies,links,lines))\n",
        "        results.append(data)\n",
        "newList = [item for sublist in results for item in sublist]\n",
        "#Creating DataFrame from the list\n",
        "df = pd.DataFrame(newList)\n",
        "#Specifying Column Names\n",
        "df.columns = ['Position', 'Company', 'HREF', 'Location' ]\n",
        "#Creating HREF Formula for Excel\n",
        "df['Link'] = 'https://www.indeed.com' + df['HREF'].astype(str)\n",
        "df['Links'] = '=HYPERLINK(\"' + df['Link'] + '\")'\n",
        "del df['HREF']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>Company</th>\n",
              "      <th>Location</th>\n",
              "      <th>Link</th>\n",
              "      <th>Links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science Intern</td>\n",
              "      <td>Stitch Fix</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=200aa5d3ed576...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Associate Data Scientist</td>\n",
              "      <td>The Walt Disney Studios</td>\n",
              "      <td>Glendale, CA</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=1d33823a58a27...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Python for Data Science-Lead</td>\n",
              "      <td>Wipro LTD</td>\n",
              "      <td>Bothell, WA</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=560aa33e18458...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020 Summer Internship- Data Science</td>\n",
              "      <td>Duke Energy</td>\n",
              "      <td>Charlotte, NC 28202 (Downtown Charlotte area)</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=bbfe97193334d...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jr Data Engineer</td>\n",
              "      <td>Chubb</td>\n",
              "      <td>United States</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=64163637daae3...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>Data Scientist - Commercial - PhD</td>\n",
              "      <td>Eli Lilly</td>\n",
              "      <td>Indianapolis, IN 46278</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=831b2847c8329...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>Machine Learning Developer - Entry level</td>\n",
              "      <td>Modern Technology Solutions, Inc.</td>\n",
              "      <td>Huntsville, AL 35806</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=3e37dc3bff8c4...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>Expert Software Engineer, Data</td>\n",
              "      <td>Walmart eCommerce</td>\n",
              "      <td>Sunnyvale, CA 94087</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=7e5a32f227673...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>Software Engineer in Big Data</td>\n",
              "      <td>Comcast</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=834d0f182f084...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Big Data Software Engineer, Batch Team</td>\n",
              "      <td>CBOE</td>\n",
              "      <td>Lenexa, KS</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=82385f324d06a...</td>\n",
              "      <td>=HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Position  ...                                              Links\n",
              "0                          Data Science Intern  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=2...\n",
              "1                     Associate Data Scientist  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=1...\n",
              "2                 Python for Data Science-Lead  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=5...\n",
              "3         2020 Summer Internship- Data Science  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=b...\n",
              "4                             Jr Data Engineer  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=6...\n",
              "...                                        ...  ...                                                ...\n",
              "4991         Data Scientist - Commercial - PhD  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...\n",
              "4992  Machine Learning Developer - Entry level  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=3...\n",
              "4993            Expert Software Engineer, Data  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=7...\n",
              "4994             Software Engineer in Big Data  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...\n",
              "4995    Big Data Software Engineer, Batch Team  ...  =HYPERLINK(\"https://www.indeed.com/rc/clk?jk=8...\n",
              "\n",
              "[4996 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFz2fLLCqlYI"
      },
      "source": [
        "#From previous list extracting all the links for different job positions to open and extract more information\n",
        "my_list = df[\"Link\"].tolist()\n",
        "results1 = []\n",
        "jobtext = []\n",
        "ratinglist = []\n",
        "#For each link, Extracting Job Description and storing into a list:\n",
        "for link in my_list:\n",
        "  r = requests.get(link)\n",
        "  r.encoding = 'utf-8'\n",
        "  html_content = r.text\n",
        "  soup1 = bs(html_content, 'lxml')\n",
        "  try:\n",
        "    for hit in soup1.find_all(\"div\", {\"class\": \"jobsearch-jobDescriptionText\"}):\n",
        "      text1 = hit.text\n",
        "    if text1:\n",
        "      jobtext.append(text1)\n",
        "    else: \n",
        "      jobtext.append('')\n",
        "  except AttributeError:\n",
        "        jobtext.append('')\n",
        "        pass\n",
        "# Extracting Date for the job posting\n",
        "  try:\n",
        "    t = [item.text.strip() for item in soup1.find_all(\"div\", {\"class\": \"jobsearch-JobMetadataFooter\"})]\n",
        "    str1 = ''.join(t)\n",
        "    date = re.search('-(.*)-', str1)\n",
        "    if date:\n",
        "      dates = date.group()\n",
        "      results1.append(dates)\n",
        "    else: \n",
        "      results1.append('')\n",
        "  except AttributeError:\n",
        "        results1.append('')\n",
        "        pass \n",
        "  # Extracting Company Rating\n",
        "  try:\n",
        "    rating = soup1.find(itemprop=\"ratingValue\").get(\"content\")\n",
        "    if rating:\n",
        "      ratinglist.append(rating)\n",
        "    else:\n",
        "      ratinglist.append('')\n",
        "  except AttributeError:\n",
        "     ratinglist.append('')\n",
        "     pass \n",
        "#Adding columns to original DataFrame\n",
        "df['Job Description'] = jobtext\n",
        "df['Posted'] = results1\n",
        "df['Company Rating'] = ratinglist\n",
        "h = df.Posted.apply(lambda x: pd.Series(str(x).split(\"-\"))) \n",
        "df['Posted'] = h[1]\n",
        "del df['Link']\n",
        "#Adding Timestamp and exporting to excel\n",
        "name = timestamp + 'BusinessIntelligenceJobs.csv'\n",
        "export_csv = df.to_csv(name, index = None, header=True)\n",
        "#Uploading the excel file to Google Cloud Platform\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# copy it there\n",
        "!cp $name \"/content/drive/My Drive/Indeed Job lists\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}